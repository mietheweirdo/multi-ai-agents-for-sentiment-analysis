{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4714c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=As5c9cI0t6Q&t! This is most likely caused by:\n",
      "\n",
      "The video is no longer available\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter, JSONFormatter\n",
    "import json\n",
    "\n",
    "def get_youtube_transcript(video_id, languages=['en'], fallback=True):\n",
    "    \"\"\"\n",
    "    Retrieve YouTube transcript (auto-generated or manual)\n",
    "    \n",
    "    Args:\n",
    "        video_id: YouTube video ID (11-character string)\n",
    "        languages: Preferred language codes (default: ['en'])\n",
    "        fallback: If True, will return auto-generated if manual not available\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'success': bool, 'transcript': str/list, 'type': str, 'language': str}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to get manual transcript first\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(\n",
    "            video_id, \n",
    "            languages=languages\n",
    "        )\n",
    "        transcript_type = \"manual\"\n",
    "        \n",
    "    except Exception as manual_error:\n",
    "        if not fallback:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(manual_error),\n",
    "                'type': 'none'\n",
    "            }\n",
    "            \n",
    "        try:\n",
    "            # Get list of available transcripts\n",
    "            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "            \n",
    "            # Find auto-generated transcript in preferred language\n",
    "            transcript = None\n",
    "            for lang in languages:\n",
    "                try:\n",
    "                    transcript = transcript_list.find_generated_transcript([lang])\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # If not found, get first available auto-generated transcript\n",
    "            if not transcript:\n",
    "                for t in transcript_list:\n",
    "                    if t.is_generated:\n",
    "                        transcript = t\n",
    "                        break\n",
    "                \n",
    "            if not transcript:\n",
    "                raise Exception(\"No auto-generated transcripts available\")\n",
    "            \n",
    "            transcript = transcript.fetch()\n",
    "            transcript_type = \"auto-generated\"\n",
    "            \n",
    "        except Exception as auto_error:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(auto_error),\n",
    "                'type': 'none'\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        'success': True,\n",
    "        'transcript': transcript,\n",
    "        'type': transcript_type,\n",
    "        'language': transcript[0].get('language', languages[0]) if transcript else ''\n",
    "    }\n",
    "\n",
    "def save_transcript(transcript_data, filename, format='text'):\n",
    "    \"\"\"Save transcript to file\"\"\"\n",
    "    if not transcript_data['success']:\n",
    "        raise ValueError(\"No transcript available to save\")\n",
    "    \n",
    "    if format == 'text':\n",
    "        formatter = TextFormatter()\n",
    "        text = formatter.format_transcript(transcript_data['transcript'])\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "            \n",
    "    elif format == 'json':\n",
    "        formatter = JSONFormatter()\n",
    "        json_data = formatter.format_transcript(transcript_data['transcript'])\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(json_data)\n",
    "            \n",
    "    elif format == 'srt':\n",
    "        from youtube_transcript_api.formatters import SRTFormatter\n",
    "        formatter = SRTFormatter()\n",
    "        srt_data = formatter.format_transcript(transcript_data['transcript'])\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(srt_data)\n",
    "            \n",
    "    return f\"Transcript saved as {filename} ({format.upper()})\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    VIDEO_ID = \"As5c9cI0t6Q&t\"  # Replace with your video ID\n",
    "    \n",
    "    # Get transcript (prefer English, fallback to auto-generated)\n",
    "    result = get_youtube_transcript(VIDEO_ID, languages=['en', 'vi'])\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"Found {result['type']} transcript in {result['language']}\")\n",
    "        \n",
    "        # Save in multiple formats\n",
    "        print(save_transcript(result, f\"{VIDEO_ID}_transcript.txt\", format='text'))\n",
    "        print(save_transcript(result, f\"{VIDEO_ID}_transcript.json\", format='json'))\n",
    "        print(save_transcript(result, f\"{VIDEO_ID}_transcript.srt\", format='srt'))\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e37075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for videos with keyword: 'iphone'\n",
      "Found 3 videos\n",
      "\n",
      "Processing video 1/3: iPhone 16 vs. iPhone 11\n",
      "Retrieved 20 comments\n",
      "\n",
      "Processing video 2/3: iPhone 17 Ultra - First Look!\n",
      "Retrieved 20 comments\n",
      "\n",
      "Processing video 3/3: iPhone 17 - 10 MAJOR Updates!\n",
      "Retrieved 20 comments\n",
      "\n",
      "Saved 60 comments to youtube_iphone_20250630_201517.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "def get_youtube_service(api_key):\n",
    "    \"\"\"Create YouTube API service instance\"\"\"\n",
    "    return build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(youtube, keyword, max_results=5):\n",
    "    \"\"\"Search YouTube videos and return top results\"\"\"\n",
    "    request = youtube.search().list(\n",
    "        part=\"id,snippet\",\n",
    "        q=keyword,\n",
    "        type=\"video\",\n",
    "        maxResults=max_results,\n",
    "        order=\"relevance\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    videos = []\n",
    "    for item in response['items']:\n",
    "        videos.append({\n",
    "            'video_id': item['id']['videoId'],\n",
    "            'title': item['snippet']['title'],\n",
    "        })\n",
    "    return videos\n",
    "\n",
    "def get_video_comments(youtube, video_id, video_title, max_comments=40):\n",
    "    \"\"\"Fetch comments for a single video\"\"\"\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    comment_count = 0\n",
    "    \n",
    "    try:\n",
    "        while comment_count < max_comments:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=min(100, max_comments - comment_count),\n",
    "                pageToken=next_page_token,\n",
    "                textFormat=\"plainText\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                content = comment['textDisplay']\n",
    "                if content.strip():\n",
    "                    comments.append({\n",
    "                        'video_title': video_title,\n",
    "                        'content': content\n",
    "                    })\n",
    "                    comment_count += 1\n",
    "                    if comment_count >= max_comments:\n",
    "                        break\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "                \n",
    "    except HttpError as e:\n",
    "        print(f\"Error getting comments for {video_id}: {e}\")\n",
    "    \n",
    "    return comments\n",
    "\n",
    "def crawl_youtube_comments(api_key, keyword, max_videos=5, max_comments=40):\n",
    "    \"\"\"Main function to crawl comments for search results\"\"\"\n",
    "    youtube = get_youtube_service(api_key)\n",
    "    \n",
    "    print(f\"Searching for videos with keyword: '{keyword}'\")\n",
    "    videos = search_videos(youtube, keyword, max_results=max_videos)\n",
    "    print(f\"Found {len(videos)} videos\")\n",
    "    \n",
    "    all_comments = []\n",
    "    for i, video in enumerate(videos, 1):\n",
    "        print(f\"\\nProcessing video {i}/{len(videos)}: {video['title']}\")\n",
    "        comments = get_video_comments(youtube, video['video_id'], video['title'], max_comments=max_comments)\n",
    "        print(f\"Retrieved {len(comments)} comments\")\n",
    "        all_comments.extend(comments)\n",
    "        \n",
    "    return all_comments\n",
    "\n",
    "def save_results(comments, keyword):\n",
    "    \"\"\"Save results to JSON file\"\"\"\n",
    "    if not comments:\n",
    "        print(\"No comments to save!\")\n",
    "        return None\n",
    "        \n",
    "    # Create filename-safe keyword\n",
    "    safe_keyword = ''.join(c if c.isalnum() else '_' for c in keyword)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"youtube_{safe_keyword}_{timestamp}.json\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(comments, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nSaved {len(comments)} comments to {filename}\")\n",
    "    return filename\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    API_KEY = \"AIzaSyAk9Ijx1Cg-eNsi3KPJHHjjT_H5zrbdEPo\"  # Replace with your YouTube API key\n",
    "    \n",
    "    # Get user input\n",
    "    keyword = input(\"Enter search keyword: \").strip()\n",
    "    max_videos = int(input(\"How many top videos to fetch? (e.g. 5): \").strip() or \"5\")\n",
    "    max_comments = int(input(\"How many comments per video? (e.g. 40): \").strip() or \"40\")\n",
    "    \n",
    "    # Execute crawl\n",
    "    comments = crawl_youtube_comments(API_KEY, keyword, max_videos=max_videos, max_comments=max_comments)\n",
    "    \n",
    "    # Save results\n",
    "    if comments:\n",
    "        save_results(comments, keyword)\n",
    "    else:\n",
    "        print(\"No comments were retrieved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
